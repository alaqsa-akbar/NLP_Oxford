{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"id":"74p2Wbe6vXZM","execution":{"iopub.status.busy":"2024-08-03T22:23:16.101966Z","iopub.execute_input":"2024-08-03T22:23:16.102450Z","iopub.status.idle":"2024-08-03T22:23:16.117049Z","shell.execute_reply.started":"2024-08-03T22:23:16.102388Z","shell.execute_reply":"2024-08-03T22:23:16.115909Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.init(mode=\"offline\")","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:23:16.118634Z","iopub.execute_input":"2024-08-03T22:23:16.118900Z","iopub.status.idle":"2024-08-03T22:23:35.830616Z","shell.execute_reply.started":"2024-08-03T22:23:16.118878Z","shell.execute_reply":"2024-08-03T22:23:35.829515Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7aa7467c9540>"},"metadata":{}}]},{"cell_type":"markdown","source":"In this Homework, you will make a Bi-directional translation model (i.e. it should do english to arabic as well as arabic to english translation) using T5-small arhcitecture. You will use Huggingface transformers library for this.\n\nTODO:\n1. Create a combined tokenization model for English and arabic using [sentencepiece](https://github.com/google/sentencepiece/blob/master/python/README.md). Don't forget to add pad_id, unk_id, bos_id, eos_id. Choose an appropriate vocabulary size.\n2. Split the data into 90:10 train and test set. Make it compaitble to be used by huggingface transformers trainer and for bi-directional training.\n3. Load the sentencepiece tokenizer into T5 tokenizer in huggingface. Study how you can do this.\n4. Load an untrained T5 small model from hugging face transformers. You will need to specify your own vocab size for embedding layer. You can also make more changes if you want.\n5. Train this model on your training data using huggingface transformers trainer. As you will be training it both way you can use a task descriptors like \"Translate from english to arabic: ...\" and \"Translate from arabic to English: ...\" before your input sentence.\n6. Evaluate your models on test data and calculate the [bleu score](https://huggingface.co/spaces/evaluate-metric/bleu). You can use the evalute model as specified in the link.\n7. Show some example inpu, true translation and generated translation from the test data. Do this for both english to arabic and arabic to english.\n\n","metadata":{"id":"o0YjgUzILAeu"}},{"cell_type":"markdown","source":"If the below code to download data doesn't work due to usage restrictions, download it directly from [here](https://drive.google.com/file/d/1APYsNu_geYk8d9vkI1e3EkLSTi4YPWDq/view?usp=sharing) and upload it your runtime.","metadata":{"id":"26aVBZCS3_tL"}},{"cell_type":"code","source":"%pip install gdown\n\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:23:35.835038Z","iopub.execute_input":"2024-08-03T22:23:35.835498Z","iopub.status.idle":"2024-08-03T22:23:49.097627Z","shell.execute_reply.started":"2024-08-03T22:23:35.835460Z","shell.execute_reply":"2024-08-03T22:23:49.096519Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import gdown\ngdown.download('https://drive.google.com/uc?export=download&id=1APYsNu_geYk8d9vkI1e3EkLSTi4YPWDq')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:23:49.100032Z","iopub.execute_input":"2024-08-03T22:23:49.100353Z","iopub.status.idle":"2024-08-03T22:23:53.105211Z","shell.execute_reply.started":"2024-08-03T22:23:49.100325Z","shell.execute_reply":"2024-08-03T22:23:53.104172Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?export=download&id=1APYsNu_geYk8d9vkI1e3EkLSTi4YPWDq\nTo: /kaggle/working/arabic_english.txt\n100%|██████████| 6.50M/6.50M [00:00<00:00, 61.2MB/s]\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'arabic_english.txt'"},"metadata":{}}]},{"cell_type":"code","source":"# !gdown \"1APYsNu_geYk8d9vkI1e3EkLSTi4YPWDq\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yom2j92Q39HK","outputId":"c7846100-3cf8-480e-f24b-0707b3fc4694","execution":{"iopub.status.busy":"2024-08-03T22:23:53.106640Z","iopub.execute_input":"2024-08-03T22:23:53.107161Z","iopub.status.idle":"2024-08-03T22:23:53.112695Z","shell.execute_reply.started":"2024-08-03T22:23:53.107130Z","shell.execute_reply":"2024-08-03T22:23:53.111676Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# %pip install datasets\n# %pip install sentencepiece\n# %pip install transformers\n%pip install evaluate\n\nclear_output()","metadata":{"id":"IPPXS4lRvDhT","execution":{"iopub.status.busy":"2024-08-03T22:23:53.113810Z","iopub.execute_input":"2024-08-03T22:23:53.114724Z","iopub.status.idle":"2024-08-03T22:24:06.335135Z","shell.execute_reply.started":"2024-08-03T22:23:53.114688Z","shell.execute_reply":"2024-08-03T22:24:06.334127Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom datasets import Dataset\nimport sentencepiece as spm\nimport numpy as np","metadata":{"id":"W2Fqkwkktr1g","execution":{"iopub.status.busy":"2024-08-03T22:24:06.337001Z","iopub.execute_input":"2024-08-03T22:24:06.337371Z","iopub.status.idle":"2024-08-03T22:24:11.804124Z","shell.execute_reply.started":"2024-08-03T22:24:06.337335Z","shell.execute_reply":"2024-08-03T22:24:11.803123Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"id":"PlnBV_oktY-C","execution":{"iopub.status.busy":"2024-08-03T22:24:11.805724Z","iopub.execute_input":"2024-08-03T22:24:11.806473Z","iopub.status.idle":"2024-08-03T22:24:11.875064Z","shell.execute_reply.started":"2024-08-03T22:24:11.806419Z","shell.execute_reply":"2024-08-03T22:24:11.873513Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\nimport random","metadata":{"id":"kPA_5Wqmte9c","execution":{"iopub.status.busy":"2024-08-03T22:24:11.876812Z","iopub.execute_input":"2024-08-03T22:24:11.877164Z","iopub.status.idle":"2024-08-03T22:24:12.477660Z","shell.execute_reply.started":"2024-08-03T22:24:11.877134Z","shell.execute_reply":"2024-08-03T22:24:12.476486Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq","metadata":{"id":"mv5_Kdf1Bud4","execution":{"iopub.status.busy":"2024-08-03T22:24:12.482747Z","iopub.execute_input":"2024-08-03T22:24:12.483071Z","iopub.status.idle":"2024-08-03T22:24:26.233580Z","shell.execute_reply.started":"2024-08-03T22:24:12.483043Z","shell.execute_reply":"2024-08-03T22:24:26.232470Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-08-03 22:24:15.582137: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-03 22:24:15.582245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-03 22:24:15.754935: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"file_path = \"arabic_english.txt\"\n\nwith open(file_path, 'r') as file:\n    lines = file.readlines()\n\ndata = [line.strip().split('\\t') for line in lines]\ndf = pd.DataFrame(data, columns=['English', 'Arabic'])\n\ndf.head(10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"qCJuJzbPtbTz","outputId":"745badd9-5d50-4061-f6a0-027c5c8573fb","execution":{"iopub.status.busy":"2024-08-03T22:24:26.238362Z","iopub.execute_input":"2024-08-03T22:24:26.239656Z","iopub.status.idle":"2024-08-03T22:24:26.621648Z","shell.execute_reply.started":"2024-08-03T22:24:26.239613Z","shell.execute_reply":"2024-08-03T22:24:26.620484Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  English   Arabic\n0     Hi.  مرحبًا.\n1    Run!    اركض!\n2   Help!  النجدة!\n3   Jump!    اقفز!\n4   Stop!      قف!\n5  Go on.    داوم.\n6  Go on.   استمر.\n7  Hello!  مرحباً.\n8  Hurry!   تعجّل!\n9  Hurry!  استعجل!","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Arabic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>مرحبًا.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>اركض!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Help!</td>\n      <td>النجدة!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump!</td>\n      <td>اقفز!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stop!</td>\n      <td>قف!</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Go on.</td>\n      <td>داوم.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Go on.</td>\n      <td>استمر.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hello!</td>\n      <td>مرحباً.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Hurry!</td>\n      <td>تعجّل!</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hurry!</td>\n      <td>استعجل!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:24:26.623058Z","iopub.execute_input":"2024-08-03T22:24:26.623472Z","iopub.status.idle":"2024-08-03T22:24:26.631082Z","shell.execute_reply.started":"2024-08-03T22:24:26.623420Z","shell.execute_reply":"2024-08-03T22:24:26.629987Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"24638"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset, test_dataset = train_test_split(df.head(10000), test_size=0.1, random_state=42) # 10000 because of cuda memory\ntrain_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)","metadata":{"id":"H8oY-iI2K2Xo","execution":{"iopub.status.busy":"2024-08-03T22:41:50.685829Z","iopub.execute_input":"2024-08-03T22:41:50.686276Z","iopub.status.idle":"2024-08-03T22:41:50.703230Z","shell.execute_reply.started":"2024-08-03T22:41:50.686240Z","shell.execute_reply":"2024-08-03T22:41:50.702167Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_dataset)\nval_dataset = Dataset.from_pandas(val_dataset)\ntest_dataset = Dataset.from_pandas(test_dataset)","metadata":{"id":"7_VdGVRbu336","execution":{"iopub.status.busy":"2024-08-03T22:41:51.169771Z","iopub.execute_input":"2024-08-03T22:41:51.170187Z","iopub.status.idle":"2024-08-03T22:41:51.217044Z","shell.execute_reply.started":"2024-08-03T22:41:51.170158Z","shell.execute_reply":"2024-08-03T22:41:51.215677Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"print(train_dataset.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FM4kPi3swC9h","outputId":"b966e170-841e-427a-f1d6-5a6a0d5238bc","execution":{"iopub.status.busy":"2024-08-03T22:41:51.219470Z","iopub.execute_input":"2024-08-03T22:41:51.220112Z","iopub.status.idle":"2024-08-03T22:41:51.227584Z","shell.execute_reply.started":"2024-08-03T22:41:51.220073Z","shell.execute_reply":"2024-08-03T22:41:51.226577Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"(8100, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('combined_text.txt', 'w', encoding='utf-8') as f:\n    for data in train_dataset:\n        f.write(data['English'] + '\\n')\n        f.write(data['Arabic'] + '\\n')","metadata":{"id":"1lYlGd8Rv45_","execution":{"iopub.status.busy":"2024-08-03T22:41:51.228993Z","iopub.execute_input":"2024-08-03T22:41:51.230023Z","iopub.status.idle":"2024-08-03T22:41:51.638331Z","shell.execute_reply.started":"2024-08-03T22:41:51.229987Z","shell.execute_reply":"2024-08-03T22:41:51.637083Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"spm.SentencePieceTrainer.train(input='combined_text.txt', model_prefix='m', vocab_size=3000, pad_id=0, unk_id=1, bos_id=2, eos_id=3)","metadata":{"id":"wfqHzrmhwaqR","execution":{"iopub.status.busy":"2024-08-03T22:41:51.639990Z","iopub.execute_input":"2024-08-03T22:41:51.640369Z","iopub.status.idle":"2024-08-03T22:41:52.644923Z","shell.execute_reply.started":"2024-08-03T22:41:51.640334Z","shell.execute_reply":"2024-08-03T22:41:52.643934Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \ntrainer_spec {\n  input: combined_text.txt\n  input_format: \n  model_prefix: m\n  model_type: UNIGRAM\n  vocab_size: 3000\n  self_test_sample_size: 0\n  character_coverage: 0.9995\n  input_sentence_size: 0\n  shuffle_input_sentence: 1\n  seed_sentencepiece_size: 1000000\n  shrinking_factor: 0.75\n  max_sentence_length: 4192\n  num_threads: 16\n  num_sub_iterations: 2\n  max_sentencepiece_length: 16\n  split_by_unicode_script: 1\n  split_by_number: 1\n  split_by_whitespace: 1\n  split_digits: 0\n  pretokenization_delimiter: \n  treat_whitespace_as_suffix: 0\n  allow_whitespace_only_pieces: 0\n  required_chars: \n  byte_fallback: 0\n  vocabulary_output_piece_score: 1\n  train_extremely_large_corpus: 0\n  seed_sentencepieces_file: \n  hard_vocab_limit: 1\n  use_all_vocab: 0\n  unk_id: 1\n  bos_id: 2\n  eos_id: 3\n  pad_id: 0\n  unk_piece: <unk>\n  bos_piece: <s>\n  eos_piece: </s>\n  pad_piece: <pad>\n  unk_surface:  ⁇ \n  enable_differential_privacy: 0\n  differential_privacy_noise_level: 0\n  differential_privacy_clipping_threshold: 0\n}\nnormalizer_spec {\n  name: nmt_nfkc\n  add_dummy_prefix: 1\n  remove_extra_whitespaces: 1\n  escape_whitespaces: 1\n  normalization_rule_tsv: \n}\ndenormalizer_spec {}\ntrainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\ntrainer_interface.cc(185) LOG(INFO) Loading corpus: combined_text.txt\ntrainer_interface.cc(409) LOG(INFO) Loaded all 16200 sentences\ntrainer_interface.cc(425) LOG(INFO) Adding meta_piece: <pad>\ntrainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\ntrainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\ntrainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\ntrainer_interface.cc(430) LOG(INFO) Normalizing sentences...\ntrainer_interface.cc(539) LOG(INFO) all chars count=391708\ntrainer_interface.cc(550) LOG(INFO) Done: 99.9556% characters are covered.\ntrainer_interface.cc(560) LOG(INFO) Alphabet size=105\ntrainer_interface.cc(561) LOG(INFO) Final character coverage=0.999556\ntrainer_interface.cc(592) LOG(INFO) Done! preprocessed 16200 sentences.\nunigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\nunigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=218948\nunigram_model_trainer.cc(312) LOG(INFO) Initialized 23917 seed sentencepieces\ntrainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 16200\ntrainer_interface.cc(609) LOG(INFO) Done! 15884\nunigram_model_trainer.cc(602) LOG(INFO) Using 15884 sentences for EM training\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10695 obj=12.1642 num_tokens=32617 num_tokens/piece=3.04974\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9304 obj=10.3253 num_tokens=32742 num_tokens/piece=3.51913\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=6967 obj=10.4175 num_tokens=35039 num_tokens/piece=5.02928\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=6955 obj=10.3515 num_tokens=35047 num_tokens/piece=5.03911\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5214 obj=10.6792 num_tokens=38714 num_tokens/piece=7.42501\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5213 obj=10.5908 num_tokens=38721 num_tokens/piece=7.42778\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3909 obj=10.9846 num_tokens=42892 num_tokens/piece=10.9726\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3909 obj=10.8947 num_tokens=42891 num_tokens/piece=10.9724\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3300 obj=11.1322 num_tokens=45376 num_tokens/piece=13.7503\nunigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3300 obj=11.0848 num_tokens=45375 num_tokens/piece=13.75\ntrainer_interface.cc(687) LOG(INFO) Saving model: m.model\ntrainer_interface.cc(699) LOG(INFO) Saving vocabs: m.vocab\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained('m.model')","metadata":{"id":"PJ-P1z6twzKK","execution":{"iopub.status.busy":"2024-08-03T22:41:52.648328Z","iopub.execute_input":"2024-08-03T22:41:52.649000Z","iopub.status.idle":"2024-08-03T22:41:52.693552Z","shell.execute_reply.started":"2024-08-03T22:41:52.648963Z","shell.execute_reply":"2024-08-03T22:41:52.691537Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2057: FutureWarning: Calling T5Tokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def find_max_token_length(dataset, tokenizer):\n    max_length = 0\n    for data in dataset:\n        for key in ('English', 'Arabic'):\n            text = data[key]\n            tokens = tokenizer.encode(text)\n            max_length = max(max_length, len(tokens))\n    return max_length\n\nmax_length = find_max_token_length(train_dataset, tokenizer)\nprint(max_length)","metadata":{"id":"JyIgifXFH1mm","execution":{"iopub.status.busy":"2024-08-03T22:41:52.694908Z","iopub.execute_input":"2024-08-03T22:41:52.695730Z","iopub.status.idle":"2024-08-03T22:41:54.860594Z","shell.execute_reply.started":"2024-08-03T22:41:52.695678Z","shell.execute_reply":"2024-08-03T22:41:54.859388Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"31\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(batch):\n    src_language = 'English'\n    tgt_language = 'Arabic'\n\n    if random.randint(0, 1) == 1:\n        src_language, tgt_language = tgt_language, src_language\n\n    prompts = [f'Translate from {src_language} to {tgt_language} ' + text for text in batch[src_language]]\n    targets = [text for text in batch[tgt_language]]\n\n#     batch['src_language'] = [src_language] * len(prompts)\n#     batch['prompt'] = prompts\n\n    inputs = tokenizer(prompts, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n    targets = tokenizer(targets, max_length=max_length, padding='max_length', truncation=True, return_tensors='pt')\n\n    batch['input_ids'] = inputs['input_ids']\n    batch['attention_mask'] = inputs['attention_mask']\n    batch['labels'] = targets['input_ids']\n\n    return batch\n","metadata":{"id":"iBGU5YUzxAFv","execution":{"iopub.status.busy":"2024-08-03T22:41:54.861902Z","iopub.execute_input":"2024-08-03T22:41:54.862292Z","iopub.status.idle":"2024-08-03T22:41:54.871090Z","shell.execute_reply.started":"2024-08-03T22:41:54.862252Z","shell.execute_reply":"2024-08-03T22:41:54.869852Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\ntokenized_val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=val_dataset.column_names)\ntokenized_test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=test_dataset.column_names)","metadata":{"id":"y2lW7myLyjBN","execution":{"iopub.status.busy":"2024-08-03T22:41:54.872578Z","iopub.execute_input":"2024-08-03T22:41:54.872899Z","iopub.status.idle":"2024-08-03T22:41:57.748095Z","shell.execute_reply.started":"2024-08-03T22:41:54.872868Z","shell.execute_reply":"2024-08-03T22:41:57.747151Z"},"trusted":true},"execution_count":80,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a076d5a0cca1407595e08cf92aab918c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd9927d7551d434598ba946ace16aa29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"856e2785919446159cb6f091c4d691b4"}},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_train_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:41:57.749273Z","iopub.execute_input":"2024-08-03T22:41:57.749576Z","iopub.status.idle":"2024-08-03T22:41:57.756743Z","shell.execute_reply.started":"2024-08-03T22:41:57.749550Z","shell.execute_reply":"2024-08-03T22:41:57.755595Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"{'input_ids': [5, 2998, 2601, 206, 325, 13, 2899, 86, 178, 2532, 109, 1342, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [146, 65, 35, 1269, 54, 2552, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame(tokenized_train_dataset[:10]).head()","metadata":{"id":"E3ijFo6wsWIh","execution":{"iopub.status.busy":"2024-08-03T22:41:57.758369Z","iopub.execute_input":"2024-08-03T22:41:57.758762Z","iopub.status.idle":"2024-08-03T22:41:57.788067Z","shell.execute_reply.started":"2024-08-03T22:41:57.758731Z","shell.execute_reply":"2024-08-03T22:41:57.787086Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"                                           input_ids  \\\n0  [5, 2998, 2601, 206, 325, 13, 2899, 86, 178, 2...   \n1  [5, 2998, 2601, 206, 325, 13, 2899, 94, 246, 8...   \n2  [5, 2998, 2601, 206, 325, 13, 2899, 91, 7, 8, ...   \n3  [5, 2998, 2601, 206, 325, 13, 2899, 90, 38, 21...   \n4  [5, 2998, 2601, 206, 325, 13, 2899, 24, 17, 5,...   \n\n                                      attention_mask  \\\n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...   \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n\n                                              labels  \n0  [146, 65, 35, 1269, 54, 2552, 4, 3, 0, 0, 0, 0...  \n1  [1642, 117, 127, 531, 817, 4, 3, 0, 0, 0, 0, 0...  \n2  [45, 591, 1245, 18, 10, 3, 0, 0, 0, 0, 0, 0, 0...  \n3  [208, 51, 369, 14, 23, 20, 396, 406, 710, 37, ...  \n4  [28, 81, 44, 18, 154, 574, 4, 3, 0, 0, 0, 0, 0...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[5, 2998, 2601, 206, 325, 13, 2899, 86, 178, 2...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n      <td>[146, 65, 35, 1269, 54, 2552, 4, 3, 0, 0, 0, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[5, 2998, 2601, 206, 325, 13, 2899, 94, 246, 8...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[1642, 117, 127, 531, 817, 4, 3, 0, 0, 0, 0, 0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[5, 2998, 2601, 206, 325, 13, 2899, 91, 7, 8, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[45, 591, 1245, 18, 10, 3, 0, 0, 0, 0, 0, 0, 0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[5, 2998, 2601, 206, 325, 13, 2899, 90, 38, 21...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[208, 51, 369, 14, 23, 20, 396, 406, 710, 37, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[5, 2998, 2601, 206, 325, 13, 2899, 24, 17, 5,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n      <td>[28, 81, 44, 18, 154, 574, 4, 3, 0, 0, 0, 0, 0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"torch.tensor(tokenized_train_dataset[0]['input_ids']).shape","metadata":{"id":"Jpap_pOIssLT","execution":{"iopub.status.busy":"2024-08-03T22:41:57.789779Z","iopub.execute_input":"2024-08-03T22:41:57.790205Z","iopub.status.idle":"2024-08-03T22:41:57.799302Z","shell.execute_reply.started":"2024-08-03T22:41:57.790174Z","shell.execute_reply":"2024-08-03T22:41:57.798237Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"torch.Size([31])"},"metadata":{}}]},{"cell_type":"code","source":"idx = 0\nrow = tokenized_test_dataset[idx]\n\n# print(f'{row[\"src_language\"]=}')\n# print(row['Arabic'])\n# print(row['English'])\n\nprint(tokenizer.decode(row['input_ids'], skip_special_tokens=True))\nprint(tokenizer.decode(row['labels'], skip_special_tokens=True))","metadata":{"id":"JvF0SoF1ty2w","execution":{"iopub.status.busy":"2024-08-03T22:41:57.800529Z","iopub.execute_input":"2024-08-03T22:41:57.800887Z","iopub.status.idle":"2024-08-03T22:41:57.824130Z","shell.execute_reply.started":"2024-08-03T22:41:57.800857Z","shell.execute_reply":"2024-08-03T22:41:57.823272Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Translate from English to Arabic I don't come here very often.\nلا آتي إلى هنا كثيرا.\n","output_type":"stream"}]},{"cell_type":"code","source":"custom_config = T5Config(\n    vocab_size=tokenizer.vocab_size,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n    bos_token_id=tokenizer.pad_token_id,\n    decoder_start_token_id=tokenizer.pad_token_id\n)","metadata":{"id":"rB2DPhsY4BEz","execution":{"iopub.status.busy":"2024-08-03T22:41:57.827375Z","iopub.execute_input":"2024-08-03T22:41:57.827696Z","iopub.status.idle":"2024-08-03T22:41:57.833658Z","shell.execute_reply.started":"2024-08-03T22:41:57.827673Z","shell.execute_reply":"2024-08-03T22:41:57.832595Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.tokenize(\"Test\"))\nprint(tokenizer.tokenize(\"اختبار\"))","metadata":{"id":"8prgxDNy28Bu","execution":{"iopub.status.busy":"2024-08-03T22:41:57.838253Z","iopub.execute_input":"2024-08-03T22:41:57.838614Z","iopub.status.idle":"2024-08-03T22:41:57.849451Z","shell.execute_reply.started":"2024-08-03T22:41:57.838583Z","shell.execute_reply":"2024-08-03T22:41:57.848401Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"['▁', 'T', 'est']\n['▁اخت', 'بار']\n","output_type":"stream"}]},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained('t5-small', config=custom_config, ignore_mismatched_sizes=True).to(device)\nmodel = torch.nn.DataParallel(model, device_ids=[0, 1]).to(device)","metadata":{"id":"eM8JYnW3_tZr","execution":{"iopub.status.busy":"2024-08-03T22:41:57.850491Z","iopub.execute_input":"2024-08-03T22:41:57.851517Z","iopub.status.idle":"2024-08-03T22:41:58.620466Z","shell.execute_reply.started":"2024-08-03T22:41:57.851482Z","shell.execute_reply":"2024-08-03T22:41:58.619265Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stderr","text":"Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-small and are newly initialized because the shapes did not match:\n- shared.weight: found shape torch.Size([32128, 512]) in the checkpoint and torch.Size([3000, 512]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n#     per_device_train_batch_size=4,\n#     per_device_eval_batch_size=4,\n    learning_rate=1e-4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n#     save_total_limit=2,\n    logging_dir='./logs',\n    remove_unused_columns=False,\n)","metadata":{"id":"vDM5mEaz_weX","execution":{"iopub.status.busy":"2024-08-03T22:41:58.622085Z","iopub.execute_input":"2024-08-03T22:41:58.622544Z","iopub.status.idle":"2024-08-03T22:41:58.670687Z","shell.execute_reply.started":"2024-08-03T22:41:58.622500Z","shell.execute_reply":"2024-08-03T22:41:58.669696Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainerCallback\n\ntrain_losses=[]\nval_losses=[]\n\nclass CustomCallback(TrainerCallback):\n    def on_log(self, args, state, control, **kwargs):\n        # Check if training loss is available in the logs\n        if \"train_loss\" in state.log_history:\n            train_loss = state.log_history[\"train_loss\"]\n            train_losses.append(train_loss)\n\n        # Check if validation loss is available in the logs\n        if \"eval_loss\" in state.log_history:\n            val_loss = state.log_history[\"eval_loss\"]\n            val_losses.append(val_loss)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:41:58.671894Z","iopub.execute_input":"2024-08-03T22:41:58.672201Z","iopub.status.idle":"2024-08-03T22:41:58.679501Z","shell.execute_reply.started":"2024-08-03T22:41:58.672175Z","shell.execute_reply":"2024-08-03T22:41:58.678337Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nbleu_metric = evaluate.load('bleu')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:41:58.680871Z","iopub.execute_input":"2024-08-03T22:41:58.681239Z","iopub.status.idle":"2024-08-03T22:41:59.354846Z","shell.execute_reply.started":"2024-08-03T22:41:58.681205Z","shell.execute_reply":"2024-08-03T22:41:59.353743Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [[label.strip()] for label in decoded_labels]\n    \n    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"bleu\"]}","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:41:59.356378Z","iopub.execute_input":"2024-08-03T22:41:59.356809Z","iopub.status.idle":"2024-08-03T22:41:59.366903Z","shell.execute_reply.started":"2024-08-03T22:41:59.356771Z","shell.execute_reply":"2024-08-03T22:41:59.366038Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='max_length', max_length=max_length)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    callbacks=[CustomCallback()],\n    compute_metrics=compute_metrics\n)","metadata":{"id":"lhZetz-bCaPs","execution":{"iopub.status.busy":"2024-08-03T22:41:59.369157Z","iopub.execute_input":"2024-08-03T22:41:59.369779Z","iopub.status.idle":"2024-08-03T22:41:59.399156Z","shell.execute_reply.started":"2024-08-03T22:41:59.369752Z","shell.execute_reply":"2024-08-03T22:41:59.398280Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"jWYbAkClCdGZ","execution":{"iopub.status.busy":"2024-08-03T22:41:59.400324Z","iopub.execute_input":"2024-08-03T22:41:59.400603Z","iopub.status.idle":"2024-08-03T22:45:48.710118Z","shell.execute_reply.started":"2024-08-03T22:41:59.400580Z","shell.execute_reply":"2024-08-03T22:45:48.709168Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m URL not available in offline run\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1521' max='1521' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1521/1521 03:48, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.377500</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.209000</td>\n      <td>No log</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.088300</td>\n      <td>No log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1521, training_loss=2.550937461978428, metrics={'train_runtime': 228.8892, 'train_samples_per_second': 106.165, 'train_steps_per_second': 6.645, 'total_flos': 0.0, 'train_loss': 2.550937461978428, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"sample_english = 'Translate from English to Arabic Test'\nwith torch.no_grad():\n    encoding = tokenizer(sample_english, return_tensors='pt')\n    input_ids, attn_mask = encoding.input_ids.to(device), encoding.attention_mask.to(device)\n    res = model.module.generate(input_ids=input_ids, attention_mask=attn_mask)\nprint(tokenizer.batch_decode(res)[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:45:54.827307Z","iopub.execute_input":"2024-08-03T22:45:54.828066Z","iopub.status.idle":"2024-08-03T22:45:55.030285Z","shell.execute_reply.started":"2024-08-03T22:45:54.828036Z","shell.execute_reply":"2024-08-03T22:45:55.029077Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"<pad>.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_losses(train_losses, val_losses):\n    plt.title('Loss vs Epochs')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.plot(train_losses)\n    plt.plot(val_losses)\n    plt.legend(['Train', 'Validation'])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:45:56.703091Z","iopub.execute_input":"2024-08-03T22:45:56.703480Z","iopub.status.idle":"2024-08-03T22:45:56.711052Z","shell.execute_reply.started":"2024-08-03T22:45:56.703418Z","shell.execute_reply":"2024-08-03T22:45:56.710192Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate()\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T22:45:58.433845Z","iopub.execute_input":"2024-08-03T22:45:58.434703Z","iopub.status.idle":"2024-08-03T22:46:04.087614Z","shell.execute_reply.started":"2024-08-03T22:45:58.434670Z","shell.execute_reply":"2024-08-03T22:46:04.086445Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"{'eval_runtime': 5.5474, 'eval_samples_per_second': 162.239, 'eval_steps_per_second': 10.275, 'epoch': 3.0}\n","output_type":"stream"}]}]}